{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temel Veri Ã–n Ä°ÅŸleme (Data Preprocessing) â€“ Teorik + UygulamalÄ± Rehber\n",
    "\n",
    "HoÅŸ geldiniz! ğŸ‘‹\n",
    "\n",
    "Bu not defteri, Veri Bilimi ve Makine Ã–ÄŸrenmesi (Machine Learning) dÃ¼nyasÄ±na adÄ±m atanlar iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r. HiÃ§bir Ã¶n bilginiz olmasa bile, adÄ±m adÄ±m ilerleyerek ham veriyi nasÄ±l analize hazÄ±r hale getireceÄŸinizi Ã¶ÄŸreneceksiniz.\n",
    "\n",
    "## ğŸ¯ Bu Rehberde Neler Ã–ÄŸreneceksiniz?\n",
    "1. **Veri Ã–n Ä°ÅŸleme Nedir?** Neden bu kadar Ã¶nemli?\n",
    "2. **Veriyi YÃ¼kleme ve Ä°nceleme:** Verimiz neye benziyor?\n",
    "3. **KeÅŸifÃ§i Veri Analizi (EDA):** Veriyi gÃ¶rselleÅŸtirme ve anlama.\n",
    "4. **Eksik Veriler (Missing Values):** KayÄ±p verilerle nasÄ±l baÅŸa Ã§Ä±karÄ±z?\n",
    "5. **AykÄ±rÄ± DeÄŸerler (Outliers):** AÅŸÄ±rÄ± uÃ§ deÄŸerleri nasÄ±l tespit ederiz?\n",
    "6. **Kategorik DeÄŸiÅŸkenler:** YazÄ± (string) verileri sayÄ±lara Ã§evirme.\n",
    "7. **Ã–zellik Ã–lÃ§eklendirme (Scaling):** Verileri aynÄ± Ã¶lÃ§eÄŸe getirme.\n",
    "8. **Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering):** Yeni Ã¶zellikler tÃ¼retme.\n",
    "9. **EÄŸitim/Test AyrÄ±mÄ± (Train/Test Split):** Modelimizi nasÄ±l test edeceÄŸiz?\n",
    "10. **TÃ¼m SÃ¼reÃ§ (Pipeline):** Hepsini birleÅŸtirelim.\n",
    "\n",
    "---\n",
    "\n",
    "## BÃ–LÃœM 1: GiriÅŸ â€“ Veri Ã–n Ä°ÅŸleme Nedir?\n",
    "\n",
    "Bir yemek yaptÄ±ÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nÃ¼n. ğŸ³ En iyi yemeÄŸi yapmak iÃ§in Ã¶nce malzemeleri yÄ±kamanÄ±z, soymanÄ±z ve doÄŸramanÄ±z gerekir. Ã‡Ã¼rÃ¼k domatesleri atar, patatesleri soyarsÄ±nÄ±z. Ä°ÅŸte **Veri Ã–n Ä°ÅŸleme** de budur.\n",
    "\n",
    "Makine Ã¶ÄŸrenmesi modelleri matematikle Ã§alÄ±ÅŸÄ±r. Kirli, eksik veya dÃ¼zensiz veriyi bu modellere verirseniz, sonuÃ§ da kÃ¶tÃ¼ olur.\n",
    "\n",
    "> **\"Garbage in, garbage out\"** (Ã‡Ã¶p girerse, Ã§Ã¶p Ã§Ä±kar) ilkesi buradan gelir.\n",
    "\n",
    "Hadi baÅŸlayalÄ±m! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 2: Veri Setini TanÄ±yalÄ±m\n",
    "\n",
    "Bu Ã§alÄ±ÅŸma iÃ§in hazÄ±rladÄ±ÄŸÄ±mÄ±z `dataset.csv` dosyasÄ±nÄ± kullanacaÄŸÄ±z. Bu verisetinde ev fiyatlarÄ± ve evlerin bazÄ± Ã¶zellikleri bulunuyor.\n",
    "\n",
    "Ä°lk iÅŸimiz kÃ¼tÃ¼phanesi Ã§aÄŸÄ±rmak ve veriyi okumak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# UyarÄ±larÄ± kapatalÄ±m (daha temiz bir gÃ¶rÃ¼ntÃ¼ iÃ§in)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Veriyi yÃ¼kleyelim\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# Ä°lk 5 satÄ±rÄ± gÃ¶relim\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ã‡Ä±ktÄ±yÄ± YorumlayalÄ±m:**\n",
    "- `Ev_Buyuklugu`: Evin metrekaresi (mÂ²)\n",
    "- `Oda_Sayisi`: OdalarÄ±n sayÄ±sÄ±\n",
    "- `Konum`: Evin bulunduÄŸu bÃ¶lge (Merkez, BanliyÃ¶, KÄ±rsal)\n",
    "- `Bina_Yasi`: BinanÄ±n yaÅŸÄ±\n",
    "- `Fiyat`: Evin satÄ±ÅŸ fiyatÄ± (Hedef deÄŸiÅŸkenimiz / Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 3: KeÅŸifÃ§i Veri Analizi (Exploratory Data Analysis - EDA)\n",
    "\n",
    "Veriyi temizlemeye baÅŸlamadan Ã¶nce, neyle karÅŸÄ± karÅŸÄ±ya olduÄŸumuzu anlamalÄ±yÄ±z. Doktorun ameliyattan Ã¶nce rÃ¶ntgen Ã§ekmesi gibidir. ğŸ©º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri seti hakkÄ±nda genel bilgi (SatÄ±r sayÄ±sÄ±, sÃ¼tun tipleri, boÅŸ deÄŸerler)\n",
    "print(\"--- Veri Seti Bilgisi ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- Ä°statistiksel Ã–zet ---\")\n",
    "# Ä°statistiksel Ã¶zet (Ortalama, standart sapma, min, max)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksik Verileri GÃ¶relim\n",
    "Hangi sÃ¼tunda kaÃ§ tane eksik (NaN - Not a Number) deÄŸer var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re bazÄ± sÃ¼tunlarda eksik verilerimiz var. BunlarÄ± birazdan halledeceÄŸiz.\n",
    "\n",
    "### GÃ¶rselleÅŸtirme\n",
    "FiyatlarÄ±n daÄŸÄ±lÄ±mÄ±na bakalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Fiyat'], kde=True)\n",
    "plt.title('Ev FiyatlarÄ± DaÄŸÄ±lÄ±mÄ±')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 4: Eksik Veriler (Missing Values) ğŸ•³\n",
    "\n",
    "Eksik veriler modelleri bozar. Onlarla baÅŸa Ã§Ä±kmak iÃ§in stratejilerimiz ÅŸunlardÄ±r:\n",
    "\n",
    "1. **Silmek (Dropping):** Veri Ã§ok fazlaysa ve eksik kÄ±sÄ±m azsa silinebilir.\n",
    "2. **Doldurmak (Imputation):** Ortalama (mean), Medyan (ortanca) veya Mod (en sÄ±k tekrar eden) ile doldurulabilir.\n",
    "\n",
    "Bizim verimizde az satÄ±r olduÄŸu iÃ§in **doldurma** yÃ¶ntemini seÃ§eceÄŸiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–nce eksik verilerin olduÄŸu satÄ±rlarÄ± bir gÃ¶relim\n",
    "print(df[df.isnull().any(axis=1)])\n",
    "\n",
    "# Stratejimiz:\n",
    "# - 'Bina_Yasi' sayÄ±sal bir deÄŸer -> ORTALAMA ile dolduralÄ±m.\n",
    "# - 'Konum' kategorik bir deÄŸer -> MOD (en sÄ±k geÃ§en) ile dolduralÄ±m.\n",
    "# - 'Ev_Buyuklugu' sayÄ±sal -> MEDYAN ile dolduralÄ±m (AykÄ±rÄ± deÄŸerlerden etkilenmez)\n",
    "\n",
    "# 1. Bina YaÅŸÄ± (Ortalama)\n",
    "yas_ortalamasi = df['Bina_Yasi'].mean()\n",
    "df['Bina_Yasi'].fillna(yas_ortalamasi, inplace=True)\n",
    "\n",
    "# 2. Ev BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (Medyan)\n",
    "buyukluk_medyan = df['Ev_Buyuklugu'].median()\n",
    "df['Ev_Buyuklugu'].fillna(buyukluk_medyan, inplace=True)\n",
    "\n",
    "# 3. Konum (Mod)\n",
    "konum_modu = df['Konum'].mode()[0]\n",
    "df['Konum'].fillna(konum_modu, inplace=True)\n",
    "\n",
    "# Kontrol edelim\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harika! ArtÄ±k eksik verimiz kalmadÄ±. âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 5: AykÄ±rÄ± DeÄŸerler (Outliers) ğŸš¨\n",
    "\n",
    "AykÄ±rÄ± deÄŸerler, genel Ã¶rÃ¼ntÃ¼ye uymayan aÅŸÄ±rÄ± uÃ§ deÄŸerlerdir. (Ã–rneÄŸin: Mahalledeki evlerin ortalamasÄ± 3 milyon TL iken, bir evin 100 milyon TL olmasÄ±).\n",
    "\n",
    "AykÄ±rÄ± deÄŸerleri tespit etmek iÃ§in **IQR (Interquartile Range)** yÃ¶ntemini kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fiyat sÃ¼tunu iÃ§in aykÄ±rÄ± deÄŸerlere bakalÄ±m\n",
    "sns.boxplot(x=df['Fiyat'])\n",
    "plt.title('Fiyat AykÄ±rÄ± DeÄŸer KontrolÃ¼ (Boxplot)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafikteki kutunun saÄŸÄ±ndaki tek nokta muhtemelen bir aykÄ±rÄ± deÄŸerdir. Hadi onu sayÄ±larla bulalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['Fiyat'].quantile(0.25)\n",
    "Q3 = df['Fiyat'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "alt_sinir = Q1 - 1.5 * IQR\n",
    "ust_sinir = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Alt SÄ±nÄ±r: {alt_sinir}\")\n",
    "print(f\"Ãœst SÄ±nÄ±r: {ust_sinir}\")\n",
    "\n",
    "# AykÄ±rÄ± deÄŸerleri gÃ¶relim\n",
    "aykirilar = df[(df['Fiyat'] < alt_sinir) | (df['Fiyat'] > ust_sinir)]\n",
    "print(\"\\nAykÄ±rÄ± DeÄŸerler:\")\n",
    "print(aykirilar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu aykÄ±rÄ± deÄŸeri verisetinden Ã§Ä±karabiliriz veya baskÄ±layabiliriz. Bu Ã¶rnekte Ã§Ä±karalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Fiyat'] >= alt_sinir) & (df['Fiyat'] <= ust_sinir)]\n",
    "\n",
    "# Ä°ndeksleri sÄ±fÄ±rlayalÄ±m\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"AykÄ±rÄ± deÄŸerler temizlendi. Yeni satÄ±r sayÄ±sÄ±:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 6: Kategorik DeÄŸiÅŸken DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Encoding) ğŸ·\n",
    "\n",
    "Bilgisayarlar kelimelerden anlamaz, sayÄ±lardan anlar. `Konum` sÃ¼tunumuzda \"Merkez\", \"KÄ±rsal\" gibi yazÄ±lar var. BunlarÄ± sayÄ±ya Ã§evirmeliyiz.\n",
    "\n",
    "Ä°ki temel yÃ¶ntem vardÄ±r:\n",
    "1. **Label Encoding:** Her kategoriye bir sayÄ± verir (Merkez=0, KÄ±rsal=1...)\n",
    "2. **One-Hot Encoding:** Her kategori iÃ§in yeni sÃ¼tun aÃ§ar (Konum_Merkez: 1 veya 0)\n",
    "\n",
    "Genellikle sÄ±ralama Ã¶nemsizse (nominal) **One-Hot Encoding** tercih edilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konum sÃ¼tununa One-Hot Encoding uygulayalÄ±m\n",
    "df_encoded = pd.get_dummies(df, columns=['Konum'], drop_first=True)\n",
    "\n",
    "print(\"Eski SÃ¼tunlar:\", df.columns.tolist())\n",
    "print(\"Yeni SÃ¼tunlar:\", df_encoded.columns.tolist())\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not: `drop_first=True` diyerek bir sÃ¼tunu attÄ±k (Dummy Variable Trap'ten kaÃ§Ä±nmak iÃ§in). Ã–rneÄŸin hem Merkez hem BanliyÃ¶ 0 ise, zaten KÄ±rsal demektir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 7: Ã–zellik Ã–lÃ§eklendirme (Feature Scaling) âš–\n",
    "\n",
    "BakÄ±n: `Fiyat` sÃ¼tunu milyonlarla ifade edilirken, `Oda_Sayisi` 3-5 gibi kÃ¼Ã§Ã¼k sayÄ±lar. Makine Ã¶ÄŸrenmesi modelleri bÃ¼yÃ¼k sayÄ±larÄ± daha \"Ã¶nemli\" sanabilir. Bunu engellemek iÃ§in hepsini aynÄ± Ã¶lÃ§eÄŸe (genelde -1 ile 1 arasÄ±na veya 0 ile 1 arasÄ±na) getiririz.\n",
    "\n",
    "**StandardScaler (StandartlaÅŸtÄ±rma):** OrtalamayÄ± 0, varyansÄ± 1 yapar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ã–lÃ§eklenecek sÃ¼tunlar (Sadece sayÄ±sal ve target olmayanlar)\n",
    "cols_to_scale = ['Ev_Buyuklugu', 'Bina_Yasi']\n",
    "\n",
    "# KopyasÄ±nÄ± alÄ±p iÅŸlem yapalÄ±m\n",
    "df_scaled = df_encoded.copy()\n",
    "\n",
    "df_scaled[cols_to_scale] = scaler.fit_transform(df_scaled[cols_to_scale])\n",
    "\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi deÄŸerler artÄ±k birbirine daha yakÄ±n aralÄ±klarda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 8: Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering) ğŸ’¡\n",
    "\n",
    "Var olan veriden, modelin daha iyi Ã¶ÄŸrenebileceÄŸi *yeni* veriler tÃ¼retme sanatÄ±dÄ±r.\n",
    "\n",
    "Ã–rnek: `Oda_Sayisi` ve `Ev_Buyuklugu` var. Acaba \"Oda baÅŸÄ±na dÃ¼ÅŸen metrekare\" fiyatÄ± etkiler mi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orijinal veriye dÃ¶nelim (okunmasÄ± kolay olsun diye)\n",
    "df['Oda_Basina_M2'] = df['Ev_Buyuklugu'] / df['Oda_Sayisi']\n",
    "\n",
    "df[['Ev_Buyuklugu', 'Oda_Sayisi', 'Oda_Basina_M2']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 9: EÄŸitim ve Test AyrÄ±mÄ± (Train / Test Split) ğŸ§©\n",
    "\n",
    "Modeli eÄŸittikten sonra ne kadar baÅŸarÄ±lÄ± olduÄŸunu gÃ¶rmek iÃ§in, verinin bir kÄ±smÄ±nÄ± \"saklarÄ±z\". Modeli verinin %80'i ile eÄŸitir, kalan %20'si ile test ederiz (sÄ±nav yaparÄ±z).\n",
    "\n",
    "Bunun iÃ§in `sklearn` kÃ¼tÃ¼phanesini kullanacaÄŸÄ±z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hedef (Target) ve Ã–zellikler (Features) ayrÄ±mÄ±\n",
    "X = df_encoded.drop('Fiyat', axis=1)  # Fiyat hariÃ§ her ÅŸey girdi\n",
    "y = df_encoded['Fiyat']               # Fiyat hedef\n",
    "\n",
    "# Veriyi bÃ¶lme\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"EÄŸitim Seti Boyutu: {X_train.shape}\")\n",
    "print(f\"Test Seti Boyutu: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 10: Mini Pipeline (Ã–zet AkÄ±ÅŸ)\n",
    "\n",
    "Åimdiye kadar parÃ§a parÃ§a yaptÄ±klarÄ±mÄ±zÄ± tek bir akÄ±ÅŸta gÃ¶relim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Veriyi YÃ¼kle\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "# 2. Eksikleri Doldur\n",
    "data['Bina_Yasi'].fillna(data['Bina_Yasi'].mean(), inplace=True)\n",
    "data['Konum'].fillna(data['Konum'].mode()[0], inplace=True)\n",
    "data['Ev_Buyuklugu'].fillna(data['Ev_Buyuklugu'].median(), inplace=True)\n",
    "\n",
    "# 3. AykÄ±rÄ± DeÄŸerleri At (BasitÃ§e)\n",
    "Q1 = data['Fiyat'].quantile(0.25)\n",
    "Q3 = data['Fiyat'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "data = data[~((data['Fiyat'] < (Q1 - 1.5 * IQR)) | (data['Fiyat'] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "# 4. Encoding\n",
    "data = pd.get_dummies(data, columns=['Konum'], drop_first=True)\n",
    "\n",
    "# 5. Split\n",
    "X = data.drop('Fiyat', axis=1)\n",
    "y = data['Fiyat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Scaling (Split'ten SONRA yapÄ±lÄ±r! Data Leakage olmamasÄ± iÃ§in)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Pipeline tamamlandÄ±. Model eÄŸitimine hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 11: YaygÄ±n BaÅŸlangÄ±Ã§ HatalarÄ± âš ï¸\n",
    "\n",
    "1. **Veri SÄ±zÄ±ntÄ±sÄ± (Data Leakage):** Scaler iÅŸlemini tÃ¼m veriye yapÄ±p sonra bÃ¶lerseniz, test verisindeki bilgiyi eÄŸitim setine sÄ±zdÄ±rmÄ±ÅŸ olursunuz. Ã–nce bÃ¶lÃ¼n, sonra X_train Ã¼zerinden `fit` yapÄ±n.\n",
    "2. **AÅŸÄ±rÄ± Temizlik:** Bazen eksik gÃ¶rÃ¼nen veriler aslÄ±nda bir bilgi taÅŸÄ±r. Her ÅŸeyi silmeyin.\n",
    "3. **Kategorik Veriyi Unutmak:** Modeller yazÄ± tipi veriyi kabul etmez, mutlaka encode edin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BÃ–LÃœM 12: Egzersizler ğŸ’ª\n",
    "\n",
    "SÄ±ra sizde! AÅŸaÄŸÄ±daki gÃ¶revleri yapmayÄ± deneyin:\n",
    "\n",
    "1. `dataset.csv` dosyasÄ±nÄ± tekrar yÃ¼kleyin.\n",
    "2. Eksik deÄŸerleri ortalama yerine 0 ile doldurun.\n",
    "3. `Oda_Sayisi` Ã¶zelliÄŸini kullanarak yeni bir Ã¶zellik tÃ¼retin (Ã¶rn: Oda sayÄ±sÄ± karesi).\n",
    "4. `StandardScaler` yerine `MinMaxScaler` kullanmayÄ± deneyin.\n",
    "\n",
    "BaÅŸarÄ±lar! ğŸ“\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
